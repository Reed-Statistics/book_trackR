# grabs an element from within a NLM document
# NAs declared to keep things explicit
#' @importFrom xml2 xml_attr
#' @importFrom magrittr %>%
extract_content <- function(raw_content) {
  # generate an empty named list
  content <- list(NA, NA)
  names(content) <- c("name", "value")
  # fill out the list
  content["name"] <- xml_attr(raw_content, "name")
  content["value"] <- xml_text(raw_content)
  # return the named list
  content
}

#takes a "row", aka a document, returned by searchnlm() and restructures it as a
#list that can be converted into a dataframe
#' @importFrom xml2 xml_attr xml_children
#' @importFrom magrittr %>%
parse_document <- function(document) {
  parsed <- document %>%
    xml_children() %>%
    purrr::map_dfr(extract_content)
  # rank uniquely identifies a document -> useful for later group_by
  parsed["rank"] <- xml_attr(document, "rank")
  # permanent url to that document (making it a valid, although verbose, unique id)
  parsed["url"] <- xml_attr(document, "url")
  parsed
}

#' Search the National Library of Medicine
#'
#' searchnlm queries the National Library of Medicine database and returns a
#' dataframe containing records on the documents captured by the query. When
#' output is set to wide, each row of the dataframe will be a document.
#' Otherwise, each row will be a field corresponding to a document.
#'
#' @param term The search term to query. By default spaces will be parsed as
#'   ANDs, and seperate elements in the vector as ORs. Use "%22" to indicate a
#'   phrase query.
#' @param field The field to query. Defaults to querying all fields. Includes
#'   choices such as "creator", "subject", "title", and "description", which are
#'   detailed below.
#' @param retmax The number of observations you want to query. Defaults to 10.
#' @param email Your email address as a string. Optional--it allows the National
#'   Library of Medicine to contact you if there are problems with your queries.
#' @param output Defaults to "tall", where each row of the returned dataframe is
#'   a value of a document. If set to "wide", each row is a document.
#' @param collapse_to_first If TRUE when output = "wide", then only the first
#'   element of that name-value pair will be included (e.g. the first date). Set
#'   to TRUE when working with dates.
#' @param print_url If TRUE, prints the URL queried
#' @example searchnlm("cholera", field = "subject")
#' @return By default, returns a dataframe where each row is a field of a record
#'   in the NLM databse. If output is set to "wide", returns a dataframe where
#'   each row is a document in the NLM database. On "wide" mode, a column can be
#'   a list containing multiple values. Rank and url uniquely identify the works
#'   in the NLM database.
#'
#' @example searchnlm("opioid")
#' @example searchnlm("cholera", retmax = 2000, output = "wide")
#'
#' @section Available Fields:
#'
#' \describe{
#'
#'   \item{Creator}{Individual author or organization responsible for the intellectual
#'   content of the resource; this field may also include contributors to the
#'   content, to the publication, or to the provenance of the resource.}
#'
#'   \item{Coverage}{Geographic subjects of the resource.}
#'
#'   \item{Date}{Publication or copyright dates.}
#'
#'   \item{Description}{Brief description of the content of the resource and/or notes
#'   regarding the resource, such as credits, gift/donor information, NLM
#'   permanence rating, et al.}
#'
#'   \item{Format}{May include the physical or digital manifestation of the resource
#'   (such as Text, Moving image, etc.), illustrative content, and extent
#'   information.}
#'
#'   \item{Identifier}{Identifiers include the Permanent URL of the resource in
#'   Digital Collections and the NLM Unique Identifier (NLMUID); other potential
#'   identifiers may include ISSN, ISBN, LCCN or OCLC numbers.}
#'
#'   \item{Language}{Language of the intellectual content of the resource. Values
#'   include English, French, German, Greek, Hawaiian, Latin, Portuguese,
#'   Spanish, etc.}
#'
#'   \item{Publisher}{Imprint statement, which may include the publisher, the
#'   distributor, the place of publication or distribution, and date(s) of
#'   publication or copyright.}
#'
#'   \item{Relation}{A reference to a related resource.}
#'
#'   \item{Rights}{Information about rights held in and over the resource.}
#'
#'   \item{Subject}{Subjects (both topical and persons) of the resource; topical
#'   subjects are from the Medical Subject Heading (MeSH) vocabulary.}
#'
#'   \item{Title}{Main and variant titles (including series titles) for the resource.}
#'
#'   \item{Type}{Nature or genre of the content of the resource.}
#'
#'   \item{Snippet}{Brief result summary generated by the search engine that provides
#'   a preview of the relevant content from the resource's full-text}
#'
#'}
#'
#' @import xml2
#' @importFrom magrittr %>%
#' @export
#' @source \url{https://collections.nlm.nih.gov/web_service.html}
searchnlm <- function(term, field = NA, retmax = NA, email = NA, output = "tall", collapse_to_first = FALSE, print_url = FALSE) {

  #############################
  # generate the URL to query #
  #############################
  # replace spaces in term with "+"
  term <- stringr::str_replace_all(term, " ", "+")
  # convert a mutli-element term to ORs, which is represented by "+OR+"
  if(length(term) > 1) {
    term <- cat(term, sep = "+OR+")
  }
  # add field to term if it exists
  if(!is.na(field)) {
    term <- paste0("dc:", field, ":", term)
  }
  # add the term prefix (must be last step)
  term <- paste0("&term=", term)
  # combine term with the base url
  url <- paste0("https://wsearch.nlm.nih.gov/ws/query?db=digitalCollections", term)
  # add retmax to url if it exists
  if(!is.na(retmax)) {
    url <- paste0(url, "&retmax=", retmax)
  }
  # add email to url if it exists
  if(!is.na(email)) {
    url <- paste0(url, "&email=", email)
  }
  if(print_url == TRUE) {
    print(url)
  }

  ##################################################
  # execute the query and parse the XML it returns #
  ##################################################
  raw_xml <- read_xml(url)
  documents <- raw_xml %>%
    # ".//document" is a single document in the NLM database
    xml_find_all(".//document")
  df <- documents %>%
    purrr::map_dfr(parse_document)
  # remove "dc:" and "dc." from name column
  df <- df %>%
    dplyr::mutate(name = stringr::str_remove(name, "dc:")) %>% # for all other fields
    dplyr::mutate(name = stringr::str_remove(name, "dc.")) # for dc.date

  ###########################
  # prepare final dataframe #
  ###########################
  output <- stringr::str_to_lower(output)
  # confirm that input for output is valid
  if(!(output %in% c("tall", "wide"))) {
    stop(output, " is not a valid input for the argument \"output\". Please input \"tall\" or \"wide\"")
  }
  # prepare final form based on output and collapse_to_first
  # structured in this weird way to prevent the NULL bug
  # wide form
  # collapse_to_first determines if list cols should be used
  if(output == "wide" & collapse_to_first == TRUE) {
    df %>%
      dplyr::group_by(rank, url) %>%
      tidyr::pivot_wider(values_fn = list(value = first)) # uses first element
  } else if(output == "wide" & collapse_to_first == FALSE) {
    df %>%
      dplyr::group_by(rank, url) %>%
      tidyr::pivot_wider(values_fn = list(value = list)) # uses list-cols for duplicates
  # is in tall form by default
  } else if(output == "tall") {
    df
  } else {
    # just a backup in case the weird NULL bug occurs again
    # where dataframes become NULL inside of this section
    df
  }

}
